"""
Script test ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra inference c√≥ ho·∫°t ƒë·ªông kh√¥ng
"""

import os
import sys

# Th√™m ƒë∆∞·ªùng d·∫´n project v√†o sys.path
BASE_PATH = os.path.dirname(os.path.abspath(__file__))
sys.path.append(BASE_PATH)

def test_imports():
    """Ki·ªÉm tra c√°c imports c·∫ßn thi·∫øt"""
    print("=" * 70)
    print("KI·ªÇM TRA IMPORTS")
    print("=" * 70)
    
    try:
        import torch
        print(f"‚úÖ torch: {torch.__version__}")
    except ImportError as e:
        print(f"‚ùå torch: {e}")
        return False
    
    try:
        import torchvision
        print(f"‚úÖ torchvision: {torch.__version__}")
    except ImportError as e:
        print(f"‚ùå torchvision: {e}")
        return False
    
    try:
        import numpy as np
        print(f"‚úÖ numpy: {np.__version__}")
    except ImportError as e:
        print(f"‚ùå numpy: {e}")
        return False
    
    try:
        import cv2
        print(f"‚úÖ cv2: {cv2.__version__}")
    except ImportError as e:
        print(f"‚ùå cv2: {e}")
        return False
    
    try:
        import matplotlib
        print(f"‚úÖ matplotlib: {matplotlib.__version__}")
    except ImportError as e:
        print(f"‚ùå matplotlib: {e}")
        return False
    
    try:
        from PIL import Image
        print(f"‚úÖ PIL (Pillow)")
    except ImportError as e:
        print(f"‚ùå PIL: {e}")
        return False
    
    print()
    return True


def test_models():
    """Ki·ªÉm tra c√°c model c√≥ t·ªìn t·∫°i kh√¥ng"""
    print("=" * 70)
    print("KI·ªÇM TRA SAVEDMODELS")
    print("=" * 70)
    
    model_dir = os.path.join(BASE_PATH, "SavedModels", "SavedModels")
    
    if not os.path.exists(model_dir):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {model_dir}")
        print("üí° ƒê·∫£m b·∫£o ƒë√£ download v√† gi·∫£i n√©n SavedModels t·ª´ OneDrive")
        return False
    
    print(f"‚úÖ Th∆∞ m·ª•c SavedModels t·ªìn t·∫°i: {model_dir}")
    print()
    
    # Ki·ªÉm tra c√°c model c·∫ßn thi·∫øt
    models_to_check = [
        ("MINI_RGBD_2D", "model.tar"),
        ("MINI_RGBD_FineTune", "model.tar"),
    ]
    
    all_exist = True
    for model_name, model_file in models_to_check:
        model_path = os.path.join(model_dir, model_name, model_file)
        if os.path.exists(model_path):
            size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            print(f"‚úÖ {model_name}/{model_file} ({size:.2f} MB)")
        else:
            print(f"‚ùå {model_name}/{model_file} - KH√îNG T√åM TH·∫§Y")
            all_exist = False
    
    print()
    return all_exist


def test_model_loading():
    """Ki·ªÉm tra c√≥ th·ªÉ load model kh√¥ng"""
    print("=" * 70)
    print("KI·ªÇM TRA LOAD MODEL")
    print("=" * 70)
    
    try:
        import torch
        from PoseEstimation.ModelArchs import ModelGenerator
        
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        print(f"Device: {device}")
        
        # T·∫°o model tr·ª±c ti·∫øp m√† kh√¥ng c·∫ßn dataset loader
        # (V√¨ ch√∫ng ta ch·ªâ c·∫ßn model ƒë·ªÉ inference, kh√¥ng c·∫ßn dataset)
        print("ƒêang t·∫°o models...")
        pose2d_model = ModelGenerator.load2DPoseEstimationModel(device)
        lifting_model = ModelGenerator.get3DLiftingNetwork(device)
        print("‚úÖ Models ƒë√£ ƒë∆∞·ª£c t·∫°o")
        
        # Load weights
        model_dir = os.path.join(BASE_PATH, "SavedModels", "SavedModels")
        pose2d_path = os.path.join(model_dir, "MINI_RGBD_2D", "model.tar")
        lifting_path = os.path.join(model_dir, "MINI_RGBD_FineTune", "model.tar")
        
        if os.path.exists(pose2d_path):
            print("ƒêang load 2D pose model...")
            checkpoint = torch.load(pose2d_path, map_location=device)
            pose2d_model.load_state_dict(checkpoint["model_state_dict"])
            pose2d_model.eval()
            print("‚úÖ 2D Pose Model ƒë√£ ƒë∆∞·ª£c load")
        else:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {pose2d_path}")
            return False
        
        if os.path.exists(lifting_path):
            print("ƒêang load 3D lifting model...")
            checkpoint = torch.load(lifting_path, map_location=device)
            lifting_model.load_state_dict(checkpoint["model_state_dict"])
            lifting_model.eval()
            print("‚úÖ 3D Lifting Model ƒë√£ ƒë∆∞·ª£c load")
        else:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {lifting_path}")
            return False
        
        print()
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        print()
        return False


def main():
    print("\n" + "=" * 70)
    print("SCRIPT TEST INFERENCE")
    print("=" * 70)
    print()
    
    # Test 1: Imports
    if not test_imports():
        print("‚ùå M·ªôt s·ªë imports b·ªã thi·∫øu. H√£y c√†i ƒë·∫∑t: pip install -r requirements.txt")
        return
    
    # Test 2: Models
    if not test_models():
        print("‚ùå M·ªôt s·ªë models b·ªã thi·∫øu. H√£y download SavedModels t·ª´ OneDrive")
        return
    
    # Test 3: Load models
    if not test_model_loading():
        print("‚ùå Kh√¥ng th·ªÉ load models. Ki·ªÉm tra l·∫°i SavedModels")
        return
    
    # T·ªïng k·∫øt
    print("=" * 70)
    print("‚úÖ T·∫§T C·∫¢ KI·ªÇM TRA ƒê√É PASS!")
    print("=" * 70)
    print()
    print("B·∫°n c√≥ th·ªÉ ch·∫°y inference b·∫±ng l·ªánh:")
    print("  python inference_simple.py --image path/to/your/image.jpg")
    print()


if __name__ == "__main__":
    main()

